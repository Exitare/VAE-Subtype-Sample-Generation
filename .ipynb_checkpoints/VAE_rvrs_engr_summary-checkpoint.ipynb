{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9b5e6-b36b-45f8-96ea-5e6408d70d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3, prep for export to repo\n",
    "# dense layer reverse engineering summary\n",
    "# Conclusion: gene expression conversion to uint8 not solving nan loss\n",
    "    # make_classification running as control, model mis-aligned with gexp data\n",
    "    # Begin devel / test cycle on alternate architechtures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616e6bd-3444-4a2e-9f96-c80efcba0544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup, dense layer architechture\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        \n",
    "        self.encoder: Model = encoder\n",
    "        self.decoder: Model = decoder\n",
    "        \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name = \"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name = \"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name = \"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss_fn = keras.losses.MeanSquaredError()\n",
    "            reconstruction_loss = reconstruction_loss_fn(data, reconstruction)\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aecdf6-94f4-4ca1-b250-a410efcd2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the latent space dimensinality\n",
    "latent_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b61697d-c2d1-4897-92a3-bd527d301e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start acquistion / format test on gene exression data\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d768526-6de9-497d-9f90-74078661601f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../gexp_files/BRCA_gxp.tsv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gxp_files = sorted(glob.glob('../gexp_files/*.tsv'))\n",
    "gxp_files[2] # <--- set cancer file n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96018a68-4582-46eb-98fe-091b92b42fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = pd.read_csv(gxp_files[2],         # <--- read TCGA breast invasive carcinoma gene expression\n",
    "                       sep = '\\t',\n",
    "                       index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9cceaf8-2e83-492f-a0ae-69d6d00111e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>N:GEXP::?:100130426:</th>\n",
       "      <th>N:GEXP::?:100133144:</th>\n",
       "      <th>N:GEXP::?:100134869:</th>\n",
       "      <th>N:GEXP::?:10357:</th>\n",
       "      <th>N:GEXP::?:10431:</th>\n",
       "      <th>N:GEXP::?:136542:</th>\n",
       "      <th>N:GEXP::?:155060:</th>\n",
       "      <th>N:GEXP::?:26823:</th>\n",
       "      <th>N:GEXP::?:280660:</th>\n",
       "      <th>...</th>\n",
       "      <th>N:GEXP::ZXDA:7789:</th>\n",
       "      <th>N:GEXP::ZXDB:158586:</th>\n",
       "      <th>N:GEXP::ZXDC:79364:</th>\n",
       "      <th>N:GEXP::ZYG11A:440590:</th>\n",
       "      <th>N:GEXP::ZYG11B:79699:</th>\n",
       "      <th>N:GEXP::ZYX:7791:</th>\n",
       "      <th>N:GEXP::ZZEF1:23140:</th>\n",
       "      <th>N:GEXP::ZZZ3:26009:</th>\n",
       "      <th>N:GEXP::psiTPTE22:387590:</th>\n",
       "      <th>N:GEXP::tAKR:389932:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRCA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AAAU</th>\n",
       "      <td>BRCA_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3640</td>\n",
       "      <td>12.932</td>\n",
       "      <td>52.150</td>\n",
       "      <td>408.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1187.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.590</td>\n",
       "      <td>1007.80</td>\n",
       "      <td>1658.5</td>\n",
       "      <td>258.49</td>\n",
       "      <td>1208.40</td>\n",
       "      <td>3507.2</td>\n",
       "      <td>1894.9</td>\n",
       "      <td>1180.50</td>\n",
       "      <td>1.7233</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-3C-AALI</th>\n",
       "      <td>BRCA_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2659</td>\n",
       "      <td>17.379</td>\n",
       "      <td>69.755</td>\n",
       "      <td>563.89</td>\n",
       "      <td>0</td>\n",
       "      <td>516.04</td>\n",
       "      <td>1.0875</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>...</td>\n",
       "      <td>59.815</td>\n",
       "      <td>448.61</td>\n",
       "      <td>1343.1</td>\n",
       "      <td>198.48</td>\n",
       "      <td>603.59</td>\n",
       "      <td>5504.6</td>\n",
       "      <td>1318.7</td>\n",
       "      <td>406.74</td>\n",
       "      <td>926.5900</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 20532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Labels  N:GEXP::?:100130426:  N:GEXP::?:100133144:  \\\n",
       "BRCA                                                               \n",
       "TCGA-3C-AAAU  BRCA_1                   0.0               16.3640   \n",
       "TCGA-3C-AALI  BRCA_4                   0.0                9.2659   \n",
       "\n",
       "              N:GEXP::?:100134869:  N:GEXP::?:10357:  N:GEXP::?:10431:  \\\n",
       "BRCA                                                                     \n",
       "TCGA-3C-AAAU                12.932            52.150            408.08   \n",
       "TCGA-3C-AALI                17.379            69.755            563.89   \n",
       "\n",
       "              N:GEXP::?:136542:  N:GEXP::?:155060:  N:GEXP::?:26823:  \\\n",
       "BRCA                                                                   \n",
       "TCGA-3C-AAAU                  0            1187.00            0.0000   \n",
       "TCGA-3C-AALI                  0             516.04            1.0875   \n",
       "\n",
       "              N:GEXP::?:280660:  ...  N:GEXP::ZXDA:7789:  \\\n",
       "BRCA                             ...                       \n",
       "TCGA-3C-AAAU             0.0000  ...             129.590   \n",
       "TCGA-3C-AALI             0.5438  ...              59.815   \n",
       "\n",
       "              N:GEXP::ZXDB:158586:  N:GEXP::ZXDC:79364:  \\\n",
       "BRCA                                                      \n",
       "TCGA-3C-AAAU               1007.80               1658.5   \n",
       "TCGA-3C-AALI                448.61               1343.1   \n",
       "\n",
       "              N:GEXP::ZYG11A:440590:  N:GEXP::ZYG11B:79699:  \\\n",
       "BRCA                                                          \n",
       "TCGA-3C-AAAU                  258.49                1208.40   \n",
       "TCGA-3C-AALI                  198.48                 603.59   \n",
       "\n",
       "              N:GEXP::ZYX:7791:  N:GEXP::ZZEF1:23140:  N:GEXP::ZZZ3:26009:  \\\n",
       "BRCA                                                                         \n",
       "TCGA-3C-AAAU             3507.2                1894.9              1180.50   \n",
       "TCGA-3C-AALI             5504.6                1318.7               406.74   \n",
       "\n",
       "              N:GEXP::psiTPTE22:387590:  N:GEXP::tAKR:389932:  \n",
       "BRCA                                                           \n",
       "TCGA-3C-AAAU                     1.7233                   0.0  \n",
       "TCGA-3C-AALI                   926.5900                   0.0  \n",
       "\n",
       "[2 rows x 20532 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29f6722-b110-463a-a46e-270d37e3dbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file.iloc[:, 1:] # get X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "994a5287-7b40-4277-9338-ae2d06b235f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.746, 0.913, 0.299, ..., 0.731, 0.738, 0.648],\n",
       "       [0.427, 0.33 , 0.499, ..., 0.594, 0.255, 0.497],\n",
       "       [0.378, 0.521, 0.514, ..., 0.45 , 0.6  , 0.358],\n",
       "       ...,\n",
       "       [0.413, 0.52 , 0.393, ..., 0.62 , 0.654, 0.455],\n",
       "       [0.625, 0.873, 0.341, ..., 0.697, 0.739, 0.776],\n",
       "       [0.592, 0.654, 0.676, ..., 0.653, 0.633, 0.532]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data # look at the synthetic data generatedd inline with make classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29856c-9c05-4329-a0a5-34f24b8f5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "495a173b-8df4-4696-9e26-0121bfbb5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split on the BRCA gene expression data\n",
    "X_train, X_val = train_test_split(file.iloc[:, 1:], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62706b96-0d1e-4ff3-a9bb-df341e4f591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c2eaf35-1d60-4ebf-8514-c1a30bc2fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796, 20531)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c69add3b-a005-467c-ac2d-8e1e5654f431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 20531)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11c1a701-8e3a-4da8-b522-db052f655e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689048f-fd20-4059-aea0-cb86ea7ff7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data type conversion on dense layer VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ec249ac8-23c7-42c5-9737-6fcc14e95110",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1cf5076-db0b-4d4b-9391-10baadfa41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a851a-6744-40f2-8fac-c299317081ae",
   "metadata": {},
   "source": [
    "Try pretraining on something then feeding floats (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1a6b1be-4d35-4b45-9d6d-1d4b84d97410",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train\n",
    "val_data = X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b0d6f80-3740-4bcf-9da4-7a7151b9cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5761c3cc-900f-472b-bf1b-a9ac7e03f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62852c9c-88f0-40d3-8eff-f82d8e96abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "35e157ed-f6c4-481f-ad80-65628fd2850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = scaler.transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb5301aa-8b77-45fc-8315-bbe43467fc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 20531)]      0           []                               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 10265)        210760980   ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 6843)         70250238    ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 5132)         35123408    ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 10)           51330       ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 10)           51330       ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " sampling_3 (Sampling)          (None, 10)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 316,237,286\n",
      "Trainable params: 316,237,286\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 5132)              56452     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 6843)              35125119  \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10265)             70253660  \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 20531)             210771246 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316,206,477\n",
      "Trainable params: 316,206,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dimensions = train_data.shape[1]\n",
    "encoder_inputs = keras.Input(shape=(input_dimensions,))\n",
    "x = layers.Dense(units=input_dimensions / 2, activation=\"relu\")(encoder_inputs)\n",
    "x = layers.Dense(units=input_dimensions / 3, activation=\"relu\")(x)\n",
    "x = layers.Dense(units=input_dimensions / 4, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(units=input_dimensions / 4, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(units=input_dimensions / 3, activation=\"relu\")(x)\n",
    "x = layers.Dense(units=input_dimensions / 2, activation=\"relu\")(x)\n",
    "decoder_outputs = layers.Dense(units=input_dimensions, activation=\"relu\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "vae: VAE = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "callbacks = []\n",
    "early_stop = EarlyStopping(monitor=\"reconstruction_loss\",\n",
    "                           mode=\"min\", patience=5, # <--------- tune early stopping here\n",
    "                           restore_best_weights=True)\n",
    "callbacks.append(early_stop)\n",
    "# csv_logger = CSVLogger(os.path.join(base_path, 'training.log'), # Is this writing a file?\n",
    "#                        separator='\\t')\n",
    "# callbacks.append(csv_logger)\n",
    "# history = vae.fit(train_data, # Fit the VAE, work backward to carve out minimum viable code path to run this function\n",
    "#                   callbacks=callbacks,\n",
    "#                   validation_data=(val_data, val_data),\n",
    "#                   epochs=500, batch_size=128)\n",
    "\n",
    "# z_mean, z_var, embedding = vae.encoder.predict(train_data)\n",
    "# embedding = pd.DataFrame(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec321309-0049-49b8-9b3e-306b5c35e8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 47s 5s/step - loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5v/88tvwqd94gs4dfr3h6rt1_w0qd13bg/T/ipykernel_38186/853434441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = vae.fit(train_data,\n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   epochs=500, batch_size=128)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = vae.fit(train_data,\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=(val_data, val_data),\n",
    "                  epochs=500, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704752b-f670-4fda-8e29-7723ed80e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732213e-29ed-49c6-9ce1-5a38134573b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e611a2a-0516-4757-a928-09465ed04364",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae: VAE = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78050e1b-df58-4749-9372-0abe2305127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VAE at 0x7fbc283ff130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae # how to inspect?, does this reset?\n",
    "# memory representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e9e02-9a1b-4e89-a69e-2402bd986461",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "370743cc-d2af-48c1-8821-e601e1460b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer=keras.optimizers.Adam()) # does this reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea725c4f-ab33-47fe-abf0-8b2903717f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edd744c1-4c11-49c6-b78e-9cf679831e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: VAE = VAE(encoder, decoder) # model is free variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed25f1f0-a67f-461f-a8e1-cf69f0a88f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "240053ae-3fff-4632-8b7d-d1d7579c41e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5v/88tvwqd94gs4dfr3h6rt1_w0qd13bg/T/ipykernel_38186/3470139634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2867\u001b[0m     \"\"\"\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2869\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   2870\u001b[0m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73be99-8489-4ce5-a855-ca59c14853c7",
   "metadata": {},
   "source": [
    "add text on sequence of fit calling (subtype burn-in)\n",
    "\n",
    "This is an idea for manuscript content based on pretraining the model on certain subtybes and final training on the subtype of interest. It also has to do with the different dimensions of the input and deconsctructing the model by saving subcomponents such as pre-trained layers to solve the dimensionality difference between the 26 TCGA cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b807b8d-99fe-4170-90f8-91184a85f1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a9fe7bd-fe79-4bbf-9ea8-0020c67a4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.637, 0.407, 0.352, ..., 0.743, 0.501, 0.618],\n",
       "       [0.81 , 0.894, 0.491, ..., 0.811, 0.686, 0.574],\n",
       "       [0.653, 0.329, 0.28 , ..., 0.964, 0.527, 0.735],\n",
       "       ...,\n",
       "       [0.39 , 0.357, 0.406, ..., 0.58 , 0.593, 0.558],\n",
       "       [0.448, 0.688, 0.579, ..., 0.455, 0.732, 0.617],\n",
       "       [0.986, 0.776, 0.577, ..., 0.561, 0.519, 0.923]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca40a73-9bb6-4434-8f20-56aeb4a2c49b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 1s 23ms/step - loss: 0.0250 - reconstruction_loss: 0.0242 - kl_loss: 8.2750e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0247 - reconstruction_loss: 0.0244 - kl_loss: 9.2560e-07 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0246 - reconstruction_loss: 0.0248 - kl_loss: 8.5582e-07 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0245 - reconstruction_loss: 0.0246 - kl_loss: 3.0201e-07 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0245 - reconstruction_loss: 0.0247 - kl_loss: 2.0436e-07 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0243 - reconstruction_loss: 0.0244 - kl_loss: 1.1495e-07 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, # run on make_classification data\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=(val_data, val_data),\n",
    "                  epochs=500, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2ef234b-db7b-4019-90b9-5b36fbe29082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to set # epochs? - says 500 but only does 7 - early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f102e97-b5fa-42b0-ba24-7c562cc1d09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# not resetting the model between runs / data sets (?)\n",
    "plt.plot(history.history['loss'],label=\"loss\")\n",
    "plt.plot(history.history['kl_loss'],label=\"kl_loss\")\n",
    "plt.title(\n",
    "    # file.index.name+\n",
    "          'Dense layer VAE embedding loss, latent dim = '+\n",
    "         str(latent_dim))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.annotate('VAE layer type: Dense\\ndtype: ?, normalized',\n",
    "            xy=(.4, .8), xycoords='figure fraction',\n",
    "            horizontalalignment='left', verticalalignment='top',\n",
    "            # fontsize=20\n",
    "            )\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('rvrs_out/'+\n",
    "            # file.index.name+'_'+\n",
    "            str(500)+'_epochs__latent_dim_'+str(latent_dim)+'_2022-08-24.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e643aa4-0c35-4a48-8974-61d7f51cb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ad84fe-e19d-40a8-9782-ea5901a267d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4c990-2170-4f03-8699-0efd579e982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the data inline\n",
    "# Ok, version 2 here put the entire VAE into one single notebook cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18f1d616-0b3d-48b5-95a5-bf6044a3f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           5050        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 33)           1683        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 25)           850         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 10)           260         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 10)           260         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 10)           0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,103\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                275       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 33)                858       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                1700      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,933\n",
      "Trainable params: 7,933\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 17:00:16.993390: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 1s 33ms/step - loss: 0.3454 - reconstruction_loss: 0.2278 - kl_loss: 0.0689 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2180 - reconstruction_loss: 0.1941 - kl_loss: 0.0122 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1658 - reconstruction_loss: 0.1516 - kl_loss: 0.0045 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1185 - reconstruction_loss: 0.1104 - kl_loss: 0.0028 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0889 - reconstruction_loss: 0.0852 - kl_loss: 0.0012 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0715 - reconstruction_loss: 0.0686 - kl_loss: 8.0843e-04 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0576 - reconstruction_loss: 0.0560 - kl_loss: 6.1356e-04 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0525 - reconstruction_loss: 0.0514 - kl_loss: 4.1067e-04 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0478 - reconstruction_loss: 0.0461 - kl_loss: 2.7458e-04 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0421 - reconstruction_loss: 0.0419 - kl_loss: 1.8591e-04 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0401 - reconstruction_loss: 0.0397 - kl_loss: 1.2373e-04 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0389 - reconstruction_loss: 0.0389 - kl_loss: 9.0558e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0366 - reconstruction_loss: 0.0366 - kl_loss: 6.9169e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0361 - reconstruction_loss: 0.0360 - kl_loss: 4.7395e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0353 - reconstruction_loss: 0.0348 - kl_loss: 3.7278e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0353 - reconstruction_loss: 0.0348 - kl_loss: 2.9629e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0343 - reconstruction_loss: 0.0338 - kl_loss: 2.6297e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0342 - reconstruction_loss: 0.0337 - kl_loss: 2.2504e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0330 - reconstruction_loss: 0.0322 - kl_loss: 2.0691e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0322 - reconstruction_loss: 0.0318 - kl_loss: 1.8151e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0308 - reconstruction_loss: 0.0307 - kl_loss: 1.6327e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0314 - reconstruction_loss: 0.0312 - kl_loss: 1.5548e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0311 - reconstruction_loss: 0.0305 - kl_loss: 1.4578e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0301 - reconstruction_loss: 0.0306 - kl_loss: 1.4043e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0289 - reconstruction_loss: 0.0292 - kl_loss: 2.3184e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0292 - reconstruction_loss: 0.0290 - kl_loss: 1.1115e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0285 - reconstruction_loss: 0.0288 - kl_loss: 1.0637e-05 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0284 - reconstruction_loss: 0.0280 - kl_loss: 9.7772e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0281 - reconstruction_loss: 0.0278 - kl_loss: 9.0993e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0277 - reconstruction_loss: 0.0275 - kl_loss: 8.5350e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0275 - reconstruction_loss: 0.0273 - kl_loss: 7.9163e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0269 - reconstruction_loss: 0.0268 - kl_loss: 7.7172e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0271 - reconstruction_loss: 0.0268 - kl_loss: 7.8841e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0268 - reconstruction_loss: 0.0268 - kl_loss: 8.7869e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0259 - reconstruction_loss: 0.0261 - kl_loss: 6.4468e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0260 - reconstruction_loss: 0.0256 - kl_loss: 6.0941e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0260 - reconstruction_loss: 0.0256 - kl_loss: 5.7793e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0256 - reconstruction_loss: 0.0255 - kl_loss: 5.4572e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0256 - reconstruction_loss: 0.0257 - kl_loss: 5.2527e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0257 - reconstruction_loss: 0.0257 - kl_loss: 5.8398e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0253 - reconstruction_loss: 0.0255 - kl_loss: 4.9824e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0248 - reconstruction_loss: 0.0251 - kl_loss: 5.1233e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0251 - reconstruction_loss: 0.0255 - kl_loss: 4.4423e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0248 - reconstruction_loss: 0.0256 - kl_loss: 4.6135e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0251 - reconstruction_loss: 0.0247 - kl_loss: 4.1215e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0254 - reconstruction_loss: 0.0246 - kl_loss: 4.1333e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0249 - reconstruction_loss: 0.0247 - kl_loss: 3.9328e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0243 - reconstruction_loss: 0.0251 - kl_loss: 3.5940e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0246 - reconstruction_loss: 0.0254 - kl_loss: 3.7954e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0248 - reconstruction_loss: 0.0244 - kl_loss: 3.2746e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0245 - reconstruction_loss: 0.0244 - kl_loss: 3.1422e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0250 - reconstruction_loss: 0.0245 - kl_loss: 3.1294e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0241 - reconstruction_loss: 0.0243 - kl_loss: 2.9226e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0246 - reconstruction_loss: 0.0246 - kl_loss: 3.0556e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0242 - reconstruction_loss: 0.0244 - kl_loss: 2.6830e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0245 - reconstruction_loss: 0.0245 - kl_loss: 2.5809e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0244 - reconstruction_loss: 0.0245 - kl_loss: 2.5145e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0243 - reconstruction_loss: 0.0246 - kl_loss: 2.4928e-06 - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n",
      "25/25 [==============================] - 0s 870us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        \n",
    "        self.encoder: Model = encoder\n",
    "        self.decoder: Model = decoder\n",
    "        \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name = \"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name = \"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name = \"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss_fn = keras.losses.MeanSquaredError()\n",
    "            reconstruction_loss = reconstruction_loss_fn(data, reconstruction)\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "latent_dim = 10\n",
    "base_path = 'rvrs_out'\n",
    "\n",
    "X, y = make_classification(n_samples=1000,\n",
    "                           n_features=100,\n",
    "                           n_informative=10,\n",
    "                           n_redundant=90,\n",
    "                           random_state=1,\n",
    "                           shift = 30)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler = scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "data = X\n",
    "\n",
    "data = np.trunc(1000 * data) / 1000\n",
    "\n",
    "X_train, X_val = train_test_split(data, test_size=0.2)\n",
    "\n",
    "train_data = X_train\n",
    "val_data = X_val\n",
    "\n",
    "input_dimensions = train_data.shape[1]\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(input_dimensions,))\n",
    "x = layers.Dense(units=input_dimensions / 2, activation=\"relu\")(encoder_inputs)\n",
    "x = layers.Dense(units=input_dimensions / 3, activation=\"relu\")(x)\n",
    "x = layers.Dense(units=input_dimensions / 4, activation=\"relu\")(x)\n",
    "\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(units=input_dimensions / 4, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Dense(units=input_dimensions / 3, activation=\"relu\")(x)\n",
    "x = layers.Dense(units=input_dimensions / 2, activation=\"relu\")(x)\n",
    "\n",
    "decoder_outputs = layers.Dense(units=input_dimensions, activation=\"relu\")(x)\n",
    "\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "vae: VAE = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "\n",
    "callbacks = []\n",
    "early_stop = EarlyStopping(monitor=\"reconstruction_loss\",\n",
    "                           mode=\"min\", patience=5,\n",
    "                           restore_best_weights=True)\n",
    "\n",
    "callbacks.append(early_stop)\n",
    "csv_logger = CSVLogger(os.path.join(base_path, 'training.log'), # Is this writing a file?\n",
    "                       separator='\\t')\n",
    "callbacks.append(csv_logger)\n",
    "history = vae.fit(train_data, # Fit the VAE, work backward to carve out minimum viable code path to run this function\n",
    "                  callbacks=callbacks,\n",
    "                  validation_data=(val_data, val_data),\n",
    "                  epochs=500, batch_size=128)\n",
    "\n",
    "z_mean, z_var, embedding = vae.encoder.predict(train_data)\n",
    "embedding = pd.DataFrame(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd57e44-bece-419a-8251-dc9d01128b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable              Type             Data/Info\n",
      "------------------------------------------------\n",
      "CSVLogger             type             <class 'keras.callbacks.CSVLogger'>\n",
      "EarlyStopping         type             <class 'keras.callbacks.EarlyStopping'>\n",
      "MinMaxScaler          type             <class 'sklearn.preproces<...>sing._data.MinMaxScaler'>\n",
      "Model                 type             <class 'keras.engine.training.Model'>\n",
      "Path                  type             <class 'pathlib.Path'>\n",
      "Sampling              type             <class '__main__.Sampling'>\n",
      "VAE                   type             <class '__main__.VAE'>\n",
      "X                     ndarray          1000x100: 100000 elems, type `float64`, 800000 bytes (781.25 kb)\n",
      "X_train               ndarray          800x100: 80000 elems, type `float64`, 640000 bytes (625.0 kb)\n",
      "X_val                 ndarray          200x100: 20000 elems, type `float64`, 160000 bytes (156.25 kb)\n",
      "base_path             str              rvrs_out\n",
      "callbacks             list             n=2\n",
      "csv_logger            CSVLogger        <keras.callbacks.CSVLogge<...>object at 0x7fbc1372e940>\n",
      "data                  ndarray          1000x100: 100000 elems, type `float64`, 800000 bytes (781.25 kb)\n",
      "decoder               Functional       <keras.engine.functional.<...>object at 0x7fbc13773d00>\n",
      "decoder_outputs       KerasTensor      KerasTensor(type_spec=Ten<...>ated by layer 'dense_6'\")\n",
      "early_stop            EarlyStopping    <keras.callbacks.EarlySto<...>object at 0x7fbc1372e6a0>\n",
      "embedding             DataFrame                    0         1  <...>\\n[800 rows x 10 columns]\n",
      "encoder               Functional       <keras.engine.functional.<...>object at 0x7fbc137793d0>\n",
      "encoder_inputs        KerasTensor      KerasTensor(type_spec=Ten<...>ated by layer 'input_1'\")\n",
      "history               History          <keras.callbacks.History <...>object at 0x7fbc137696d0>\n",
      "input_dimensions      int              100\n",
      "json                  module           <module 'json' from '/Use<...>hon3.9/json/__init__.py'>\n",
      "keras                 module           <module 'keras.api._v2.ke<...>i/_v2/keras/__init__.py'>\n",
      "latent_dim            int              10\n",
      "latent_inputs         KerasTensor      KerasTensor(type_spec=Ten<...>ated by layer 'input_2'\")\n",
      "layers                module           <module 'keras.api._v2.ke<...>eras/layers/__init__.py'>\n",
      "make_classification   function         <function make_classification at 0x7fbc12000dc0>\n",
      "np                    module           <module 'numpy' from '/Us<...>kages/numpy/__init__.py'>\n",
      "os                    module           <module 'os' from '/Users<...>da3/lib/python3.9/os.py'>\n",
      "pd                    module           <module 'pandas' from '/U<...>ages/pandas/__init__.py'>\n",
      "plt                   module           <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "scaler                MinMaxScaler     MinMaxScaler()\n",
      "tf                    module           <module 'tensorflow' from<...>/tensorflow/__init__.py'>\n",
      "train_data            ndarray          800x100: 80000 elems, type `float64`, 640000 bytes (625.0 kb)\n",
      "train_test_split      function         <function train_test_split at 0x7fbc1209a310>\n",
      "vae                   VAE              <__main__.VAE object at 0x7fbc13795670>\n",
      "val_data              ndarray          200x100: 20000 elems, type `float64`, 160000 bytes (156.25 kb)\n",
      "x                     KerasTensor      KerasTensor(type_spec=Ten<...>ated by layer 'dense_5'\")\n",
      "y                     ndarray          1000: 1000 elems, type `int64`, 8000 bytes\n",
      "z                     KerasTensor      KerasTensor(type_spec=Ten<...>ted by layer 'sampling'\")\n",
      "z_log_var             KerasTensor      KerasTensor(type_spec=Ten<...>ed by layer 'z_log_var'\")\n",
      "z_mean                ndarray          800x10: 8000 elems, type `float32`, 32000 bytes\n",
      "z_var                 ndarray          800x10: 8000 elems, type `float32`, 32000 bytes\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d4c9f0-8569-49c1-a6fc-64feaa43d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9df15b-49f7-4395-98fa-726a6a5370db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467896545746182"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27f5c2d-e096-432f-9349-5f7b7f7b0969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89307beb-ef05-4ae0-a4a5-e950b0abaa3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original good run on the in-line make classification data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'],label=\"loss\")\n",
    "plt.plot(history.history['kl_loss'],label=\"kl_loss\")\n",
    "plt.title(\n",
    "    # file.index.name+\n",
    "          'Dense layer VAE embedding loss, latent dim = '+\n",
    "         str(latent_dim))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.annotate('VAE layer type: Dense\\ndtype: ?, normalized',\n",
    "            xy=(.4, .8), xycoords='figure fraction',\n",
    "            horizontalalignment='left', verticalalignment='top',\n",
    "            # fontsize=20\n",
    "            )\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig('rvrs_out/'+\n",
    "            # file.index.name+'_'+\n",
    "            str(500)+'_epochs__latent_dim_'+str(latent_dim)+'_2022-08-17_v4.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
